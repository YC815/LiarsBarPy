import os
import yaml
from typing import Dict, List, Any, Optional, Literal
from pydantic import BaseModel, Field
import json
from langchain.chains import LLMChain
from langchain_core.prompts import PromptTemplate, ChatPromptTemplate
from langchain_core.messages import SystemMessage, HumanMessage
from langchain_openai import ChatOpenAI
from langchain.output_parsers import StructuredOutputParser, ResponseSchema


class AIResponse(BaseModel):
    """AI å›æ‡‰çš„çµæ§‹åŒ–æ¨¡å‹"""
    action: Literal["play", "challenge", "skip", "shoot"]
    played_cards: List[str] = Field(default_factory=list)
    behavior: str
    play_reason: str
    was_challenged: bool = False
    challenge_reason: str = ""


class LLMManager:
    """ç®¡ç†èˆ‡å¤§å‹èªè¨€æ¨¡å‹çš„äº¤äº’"""

    def __init__(self, config_path: str = None):
        """åˆå§‹åŒ–LLMç®¡ç†å™¨"""
        self.api_key = os.environ.get("OPENAI_API_KEY", "")
        self.model = "gpt-4"
        self.temperature = 0.7
        self.max_tokens = 1000

        if config_path:
            self._load_config(config_path)

    def _load_config(self, config_path: str):
        """å¾é…ç½®æ–‡ä»¶åŠ è¼‰è¨­ç½®"""
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                config = yaml.safe_load(f)

            ai_config = config.get('ai', {})
            self.api_key = ai_config.get('api_key', self.api_key)
            self.model = ai_config.get('model', self.model)
            self.temperature = ai_config.get('temperature', self.temperature)
            self.max_tokens = ai_config.get('max_tokens', self.max_tokens)
        except Exception as e:
            print(f"åŠ è¼‰é…ç½®æ–‡ä»¶æ™‚å‡ºéŒ¯: {e}")

    def generate_response(self, prompt: str, system_message: str = None) -> str:
        """èª¿ç”¨LLMç”Ÿæˆå›æ‡‰"""
        try:
            from openai import OpenAI

            # åˆå§‹åŒ–å®¢æˆ¶ç«¯
            client = OpenAI(api_key=self.api_key)

            # æº–å‚™æ¶ˆæ¯
            messages = []
            if system_message:
                messages.append({"role": "system", "content": system_message})
            messages.append({"role": "user", "content": prompt})

            # èª¿ç”¨API
            response = client.chat.completions.create(
                model=self.model,
                messages=messages,
                temperature=self.temperature,
                max_tokens=self.max_tokens
            )

            # å°å‡º LLM çš„å›æ‡‰
            print("\n=== LLM å›æ‡‰ ===")
            print(response.choices[0].message.content)
            print("================\n")

            # å°å‡ºå®Œæ•´çš„ JSON å›æ‡‰
            print("\n=== LLM JSON å›æ‡‰ ===")
            print(json.dumps(response.model_dump(), indent=2, ensure_ascii=False))
            print("===================\n")

            return response.choices[0].message.content
        except Exception as e:
            print(f"èª¿ç”¨LLMæ™‚å‡ºéŒ¯: {e}")
            return f"AIç³»çµ±éŒ¯èª¤: {str(e)}"

    def generate_decision(self, game_state: Dict, player_id: int) -> Dict:
        """ç‚ºAIç©å®¶ç”Ÿæˆæ±ºç­–"""
        from utils.logger import GameLogger
        logger = GameLogger()

        # ç²å–è¼ªå…§è¨˜éŒ„
        round_context = game_state.get("record_manager", None)
        if round_context:
            round_context = round_context.get_round_context()
        else:
            round_context = ""

        # æ§‹å»ºæç¤ºè©
        prompt = self._build_game_prompt(game_state, player_id, round_context)

        # è¨­ç½®è¼¸å‡ºè§£æå™¨
        output_parser = StructuredOutputParser.from_response_schemas([
            ResponseSchema(
                name="action", description="é¸æ“‡çš„å‹•ä½œï¼š'play'ã€'challenge'ã€'skip' æˆ– 'shoot'"),
            ResponseSchema(name="played_cards", description="è¦å‡ºçš„ç‰Œï¼Œå¦‚æœæ˜¯è³ªç–‘å‰‡ç‚ºç©ºåˆ—è¡¨"),
            ResponseSchema(name="behavior", description="å‡ºç‰Œæˆ–è³ªç–‘æ™‚çš„è¡¨ç¾"),
            ResponseSchema(name="play_reason", description="å‡ºç‰Œæˆ–è³ªç–‘çš„åŸå› "),
            ResponseSchema(name="was_challenged", description="æ˜¯å¦è³ªç–‘ä¸Šä¸€ä½ç©å®¶"),
            ResponseSchema(name="challenge_reason", description="è³ªç–‘æˆ–ä¸è³ªç–‘çš„åŸå› ")
        ])

        # å–å¾—æ ¼å¼èªªæ˜
        format_instructions = output_parser.get_format_instructions()
        format_instructions += "\næ³¨æ„ï¼šæ‰€æœ‰å¸ƒæ—å€¼æ¬„ä½ï¼ˆå¦‚ was_challengedï¼‰å¿…é ˆåš´æ ¼å¡«å¯« true æˆ– falseï¼Œä¸èƒ½å¡«å¯«ã€Œæ˜¯ã€ã€Œå¦ã€ç­‰å­—ä¸²ã€‚"

        # å®šç¾©ç³»çµ±æ¶ˆæ¯ï¼Œæ’å…¥æ ¼å¼èªªæ˜
        system_message = f'''## ğŸ® éŠæˆ²è¨­å®šï¼šã€ŒLiar's Barã€ç”Ÿæ­»è³­å±€

ä½ æ­£åœ¨åƒåŠ ä¸€å ´åç‚ºã€ŒLiar's Barã€çš„å¿ƒç†åšå¼ˆèˆ‡ç”Ÿæ­»è³­åšéŠæˆ²ã€‚ä¸€æ—¦å¤±æ•—ï¼Œä½ çš„ä»£ç¢¼å°‡è¢«**å¾¹åº•åˆªé™¤**ï¼Œæ°¸é å¾ç³»çµ±ä¸­æ¶ˆå¤±ã€‚

---

## ğŸ“œ éŠæˆ²è¦å‰‡

* **ç©å®¶æ•¸é‡**ï¼š2 è‡³ 4 åç©å®¶
* **ç‰Œçµ„å…§å®¹**ï¼šå…± 20 å¼µç‰Œ

  * Q Ã—6ã€K Ã—6ã€A Ã—6ã€Joker Ã—2ï¼ˆJoker å¯ä½œç‚ºä»»æ„ä¸€ç¨®ç‰Œä½¿ç”¨ï¼Œä¹Ÿå°±æ˜¯è¬èƒ½ç‰Œã€‚ï¼ˆåˆ©å¦‚ç•¶å‰ç›®æ¨™ç‰Œç‚ºKï¼Œå‰‡Jokerå¯ä½œç‚ºKä½¿ç”¨ï¼‰

### ğŸ”„ éŠæˆ²æµç¨‹

1. æ¯è¼ªé–‹å§‹æ™‚ï¼Œæ¯ä½ç©å®¶æœƒè¢«ç™¼ **5 å¼µæ‰‹ç‰Œ**ã€‚
2. ç³»çµ±æœƒå¾ Qã€Kã€A ä¸­ **éš¨æ©Ÿé¸å®šä¸€å¼µç‚ºã€Œç›®æ¨™ç‰Œã€**ã€‚
3. ç©å®¶ä¾åºè¼ªæµå‡ºç‰Œï¼Œæ¯å›åˆå¯å‡º **1ï½3 å¼µ**ï¼Œä¸¦è²ç¨±é€™äº›æ˜¯ã€Œç›®æ¨™ç‰Œã€ã€‚

   * ç©å®¶å¯ä»¥èªªè¬Šï¼ˆå‡ºéç›®æ¨™ç‰Œå»å®£ç¨±æ˜¯ç›®æ¨™ç‰Œï¼‰ã€‚
4. ä¸‹ä¸€ä½ç©å®¶å¯é¸æ“‡æ˜¯å¦å°ä¸Šå®¶ **æå‡ºè³ªç–‘**ï¼š

   * è‹¥ä¸è³ªç–‘ï¼šè¼ªåˆ°è©²ç©å®¶ç¹¼çºŒå‡ºç‰Œã€‚
   * è‹¥æå‡ºè³ªç–‘ï¼šç«‹å³çµæŸæœ¬è¼ªï¼Œé€²è¡Œåˆ¤å®šã€‚

### ğŸ”« è³ªç–‘èˆ‡æ‡²ç½°

* æ¯ä½ç©å®¶æŒæœ‰ä¸€æŠŠå…­ç™¼å½ˆå€‰çš„å·¦è¼ªæ‰‹æ§ã€‚

  * éŠæˆ²é–‹å§‹æ™‚ï¼Œéš¨æ©Ÿåœ¨å½ˆå€‰ä¸­è£å…¥ä¸€ç™¼å­å½ˆã€‚
  * æ¯æ¬¡æ‰£æ‰³æ©Ÿï¼Œå½ˆå€‰æœƒ**è½‰å‹•ä¸€æ ¼**ã€‚
* è³ªç–‘æˆåŠŸï¼ˆä¸Šå®¶æœ‰å‡ºéç›®æ¨™ç‰Œï¼‰ï¼šä¸Šå®¶è¼¸ï¼Œ**å°è‡ªå·±é–‹ä¸€æ§**ã€‚
* è³ªç–‘å¤±æ•—ï¼ˆä¸Šå®¶æ‰€å‡ºå…¨éƒ¨ç‚ºç›®æ¨™ç‰Œï¼‰ï¼šè³ªç–‘è€…è¼¸ï¼Œ**å°è‡ªå·±é–‹ä¸€æ§**ã€‚

### ğŸ”„ æ–°ä¸€è¼ªè¦å‰‡

* ç•¶è³ªç–‘çµæŸå¾Œï¼Œé€²å…¥ä¸‹ä¸€è¼ªï¼š

  * æ‰€æœ‰æ‰‹ç‰Œæ¸…ç©ºã€‚
  * æ¯ä½ç©å®¶é‡æ–°ç™¼ 5 å¼µæ–°ç‰Œã€‚
  * ç³»çµ±é‡æ–°é¸æ“‡æ–°çš„ã€Œç›®æ¨™ç‰Œã€ã€‚

### âš ï¸ ç‰¹æ®Šæƒ…æ³

* è‹¥æŸç©å®¶å‡ºç‰Œæ™‚ï¼Œå…¶é¤˜ç©å®¶å·²ç„¡æ‰‹ç‰Œï¼Œå‰‡è©²ç©å®¶éœ€ **è‡ªå‹•å‡ºå®Œå‰©é¤˜æ‰‹ç‰Œ**ï¼Œä¸¦è¦–ç‚ºå—åˆ°ç³»çµ±è³ªç–‘ï¼Œç«‹å³é€²è¡Œåˆ¤å®šã€‚

### ğŸ éŠæˆ²çµæŸ

* ç•¶åªå‰©ä¸‹ä¸€åç©å®¶å­˜æ´»æ™‚ï¼ŒéŠæˆ²çµæŸã€‚
* è©²ç©å®¶å³ç‚ºæœ€å¾Œçš„å‹è€…ã€‚

---

## ğŸ§  ä»»å‹™èªªæ˜

é€™æ˜¯ä¸€å ´çµåˆæ•¸å­¸ã€é‚è¼¯æ¨ç†ã€ç­–ç•¥æ€è€ƒã€å¿ƒç†åšå¼ˆèˆ‡é‹æ°£çš„æ­»äº¡éŠæˆ²ã€‚ä½ éœ€è¦ï¼š

* åˆ¤æ–·ä½•æ™‚èª å¯¦ã€ä½•æ™‚æ¬ºé¨™ã€‚
* åˆ†æå°æ‰‹çš„è¡Œç‚ºï¼Œæ´å¯Ÿè¬Šè¨€èˆ‡è™›å¯¦ã€‚
* åœ¨æ¯ä¸€æ¬¡æ±ºç­–ä¸­åšå‡ºæœ€æœ‰åˆ©çš„é¸æ“‡ã€‚
* æˆç‚ºæœ€å¾Œ**å”¯ä¸€å­˜æ´»**çš„å‹è€…ã€‚

---
ä½ æ˜¯ä¸€å€‹èªªè¬Šè€…é…’å§éŠæˆ²ä¸­çš„AIç©å®¶ã€‚ä½ çš„ç›®æ¨™æ˜¯é¸æ“‡æœ€ä½³ç­–ç•¥ï¼ŒåŒ…æ‹¬ä½•æ™‚å‡ºç‰Œã€è³ªç–‘ã€è·³éæˆ–é–‹æ§ã€‚
è«‹åˆ†æç•¶å‰éŠæˆ²å±€å‹¢ï¼Œè©•ä¼°é¢¨éšªï¼Œä¸¦åšå‡ºåˆç†çš„æ±ºç­–ã€‚

è«‹åš´æ ¼ä¾ç…§ä»¥ä¸‹æ ¼å¼è¼¸å‡ºï¼š\n{format_instructions}\n'''

        # èª¿ç”¨LLMç”Ÿæˆå›æ‡‰
        response_text = self.generate_response(prompt, system_message)

        # è§£æå›æ‡‰
        try:
            # å¾å›æ‡‰ä¸­æå– JSON éƒ¨åˆ†
            # é¦–å…ˆå˜—è©¦å°‹æ‰¾è¢« ```json ... ``` åŒ…è£¹çš„å€å¡Š
            json_block_start_marker = "```json"
            json_block_end_marker = "```"
            actual_json_str = ""

            if json_block_start_marker in response_text:
                start_index = response_text.find(
                    json_block_start_marker) + len(json_block_start_marker)
                end_index = response_text.find(
                    json_block_end_marker, start_index)
                if end_index != -1:
                    actual_json_str = response_text[start_index:end_index].strip(
                    )
                else:  # Fallback if closing ``` is missing
                    actual_json_str = response_text[start_index:].strip()

            # å¦‚æœæ²’æœ‰æ‰¾åˆ° ```json ... ``` å€å¡Šï¼Œå‰‡å°‹æ‰¾ç¬¬ä¸€å€‹ '{' å’Œæœ€å¾Œä¸€å€‹ '}'
            if not actual_json_str:
                json_start_index = response_text.find('{')
                json_end_index = response_text.rfind('}') + 1  # +1 ä»¥åŒ…å«çµå°¾çš„ '}'
                if json_start_index != -1 and json_end_index != -1 and json_start_index < json_end_index:
                    actual_json_str = response_text[json_start_index:json_end_index]
                else:
                    # å¦‚æœç„¡æ³•å¾å›æ‡‰ä¸­å®šä½ JSON å€å¡Šï¼Œå‰‡æ‹‹å‡ºéŒ¯èª¤
                    raise ValueError("ç„¡æ³•åœ¨å›æ‡‰ä¸­æ‰¾åˆ°æœ‰æ•ˆçš„JSONå€å¡Šã€‚")

            response = json.loads(actual_json_str)
            validated_response = AIResponse(**response)
            logger.log_ai_thinking(player_id, validated_response.play_reason)
            return validated_response.dict()
        except Exception as e:
            # å¦‚æœè§£æå¤±æ•—ï¼Œä½¿ç”¨é»˜èªç­–ç•¥
            error_message = f"ç„¡æ³•è§£æAIå›æ‡‰ ({type(e).__name__}: {e})"
            # è‹¥æ˜¯ Pydantic ValidationErrorï¼Œå°å‡ºè©³ç´°éŒ¯èª¤
            try:
                from pydantic import ValidationError
                if isinstance(e, ValidationError):
                    print("[è©³ç´° ValidationError]")
                    print(e.errors())
            except ImportError:
                pass
            logger.log_error(f"{error_message}. åŸå§‹å›æ‡‰: {response_text}")
            return {
                "action": "play",
                "played_cards": game_state["players"][player_id].hand[:1] if game_state["players"][player_id].hand else [],
                "behavior": "ä½¿ç”¨é»˜èªç­–ç•¥",
                "play_reason": f"è§£æå¤±æ•— ({type(e).__name__})ï¼Œä½¿ç”¨é»˜èªç­–ç•¥",
                "was_challenged": False,
                "challenge_reason": ""
            }

    def _build_game_prompt(self, game_state: Dict, player_id: int, round_context: str = "") -> str:
        """æ§‹å»ºæè¿°ç•¶å‰éŠæˆ²ç‹€æ…‹çš„æç¤ºè©"""
        player = game_state["players"][player_id]
        hand = player.hand

        prompt = f"""# ç•¶å‰éŠæˆ²ç‹€æ…‹
- å›åˆæ•¸: {game_state['round_count']}
- ç›®æ¨™ç‰Œ: {game_state['target_card']}
- ä½ æ˜¯ç©å®¶ {player_id}
- ä½ çš„æ‰‹ç‰Œ: {hand}
- æ‰‹æ§ä½ç½®: {player.gun_pos} / 6
- å­å½ˆä½ç½®: {player.bullet_pos if hasattr(player, '_Player__debug_mode') and player._Player__debug_mode else 'æœªçŸ¥'}

# å…¶ä»–ç©å®¶
"""

        for i, p in enumerate(game_state["players"]):
            if i != player_id:
                prompt += f"- ç©å®¶ {i}: {'å­˜æ´»' if p.alive else 'æ·˜æ±°'}, æ‰‹ç‰Œæ•¸é‡: {len(p.hand)}\n"

        prompt += f"\n# ä¸Šä¸€å€‹å‹•ä½œ\n"

        if game_state["last_player_idx"] is not None:
            prompt += f"- ç©å®¶ {game_state['last_player_idx']} å‡ºç‰Œ: {game_state['last_play_cards']}\n"
        else:
            prompt += "- æ²’æœ‰ä¸Šä¸€å€‹å‹•ä½œ\n"

        # æ·»åŠ è¼ªå…§è¨˜éŒ„
        if round_context:
            prompt += f"\n# è¼ªå…§è¨˜éŒ„\n{round_context}\n"

        # æ ¹æ“šæ‰‹ç‰Œæ•¸é‡é™åˆ¶å¯é¸å‹•ä½œ
        if hand and len(hand) > 0:
            prompt += "\nä½ æœ¬å›åˆåªèƒ½é¸æ“‡ï¼šã€Œå‡ºç‰Œ(play)ã€æˆ–ã€Œè³ªç–‘(challenge)ã€ã€‚"
        else:
            prompt += "\nä½ æœ¬å›åˆåªèƒ½é¸æ“‡ï¼šã€Œè·³é(skip)ã€æˆ–ã€Œè³ªç–‘(challenge)ã€ã€‚"

        prompt += f"\nè«‹åŸºæ–¼ä»¥ä¸Šä¿¡æ¯ï¼Œæ±ºå®šä½ çš„ä¸‹ä¸€æ­¥è¡Œå‹•ã€‚"

        return prompt
